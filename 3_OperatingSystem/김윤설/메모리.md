# 메모리 계층

메모리를 필요에 따라 여러가지 종류로 나누어 두어 CPU가 메모리에 더 빨리 접근하도록 하기 위함

- 레지스터
    
    CPU가 요청을 처리하는데 필요한 데이터를 일시적으로 저장하는 기억장치
    
    속도가 가장 빠르며 기억 용량이 가장 적음
    
    컴퓨터의 4대 주요 기능(기억, 해석, 연산, 제어)을 관할
    
    - CPU 내부 레지스터 종류
        
        
        | 종류 | 설명 |
        | --- | --- |
        | 프로그램 계수기
        (PC, Program Counter) | 다음에 실행할 명령어의 주소를 가지고 있는 레지스터 |
        | 누산기
        (AC, ACcumulator) | 연산 결과 데이터를 일시적으로 저장하는 레지스터 |
        | 명령어 레지스터
        (IR, Instruction Register) | 현재 수행 중인 명령어를 가지고 있는 레지스터 |
        | 상태 레지스터
        (SR, Status Register) | 현재 CPU의 상태를 가지고 있는 레지스터 |
        | 메모리 주소 레지스터
        (MAR, Memory Address Register) | 메모리로부터 읽어오거나 메모리에 쓰기 위한 주소를 가지고 있는 레지스터 |
        | 메모리 버퍼 레지스터
        (MBR, Memory Buffer Register) | 메모리로부터 읽어온 데이터 또는 메모리에 써야할 데이터를 가지고 있는 레지스터 |
        | 입출력 주소 레지스터
        (I/O AR, I/O Address Register) | 입출력 장치에 따른 입출력 모듈의 주소를 가지고 있는 레지스터 |
        | 입출력 버퍼 레지스터
        (I/O BR, I/O Buffer Register) | 입출력 모듈과 프로세서 간의 데이터 교환을 위해 사용되는 레지스터 |
- 캐시
    
    데이터를 미리 복사해 놓는 임시 저장소이자 장치 간 속도 차이에 따른 병목 현상을 줄이기 위한 메모리
    
    <aside>
    💡 캐싱: 캐시라고 하는 메모리 영역으로 데이터를 가져와서 접근하는 접근 방식
    
    </aside>
    
    캐시가 효율적으로 동작하기 위해서는 캐시가 저장할 데이터가 지역성을 가져야 함
    
    캐시의 종류
    
    - CPU 캐시: 대용량의 메인 메모리 접근을 빠르게 하기 위해 CPU 칩 내부나 바로 옆에 탑재하는 작은 메모리 (하드웨어를 통해 관리)
        
        
        | 종류 | 설명 | CPU 성능에 직접적으로 영향을 미치는지 여부 |
        | --- | --- | --- |
        | L1 캐시 | 일반적으로 CPU 칩 안에 내장되어 데이터 사용 및 참조에 가장 먼저 사용되는 캐시 메모리 | O |
        | L2 캐시 | L1 캐시 메모리와 용도와 역할이 비슷하나 속도가 더 느림 | O |
        | L3 캐시 | L1, L2 캐시와 동일한 원리로 작동하고 CPU가 아닌 메인보드에 내장되어 있음 | X |
    - 디스크 캐시: 하드디스크에 내장되어 디스크 제어, 외부와의 인터페이스를 하는 작은 컴퓨터가 소유한 작은 메모리
    - 페이지 캐시: 운영체제의 메인 메모리를 하드 디스크에 복사해 놓는 캐시
- 주기억장치
    
    컴퓨터에서 수치, 명령, 자료 등을 기억하는 컴퓨터 하드웨어 장치
    
    주기억장치 구성
    
    - RAM(Random Access Memory): 휘발성 기억 장치로 전원이 꺼지면 기억된 내용이 모두 사라짐
        - DRAM: 동적 메모리, 주로 주기억장치를 말함
        - SRAM: 정적 메모리, 주로 캐시 메모리나 레지스터로 사용됨
    - ROM(Read Only Memory): 고정 기억 장치로 비휘발성 메모리이기 때문에 전원이 꺼져도 기억된 내용이 지워지지 않음
        
        주기억장치로 사용되기보다는 기본 입출력 시스템(BIOS), 자가 진단 프로그램(POST) 같은 변경 가능성이 희박한 시스템 소프트웨어를 기억시키는데 이용
        
- 보조기억장치
    
    중앙처리장치에서 요청이 오면 저장하고 있던 프로그램과 데이터를 주기억장치로 전송하는 역할 (하드디스크, SSD)
    

### 지역성

캐시의 적중률을 극대화시키기 위한 개념으로 어느 한 순간에 특정 부분을 집중적으로 참조하는 특성

- 시간 지역성: 최근 사용한 데이터에 다시 접근하려는 특성
    
    → 메모리 상 같은 주소에 여러 차례 읽기, 쓰기를 수행하는 경우 상대적으로 작은 크기의 캐시를 사용해도 효율성이 향상됨
    
- 공간 지역성: 최근 접한 데이터를 이루고 있는 공간이나 가까운 공간에 접근하려는 특성
    
    → 캐시에 이미 저장된 같은 블록의 데이터를 접근하면 캐시의 효율성이 향상됨
    

## 캐시히트와 캐시미스

캐시히트: 캐시에서 원하는 데이터를 찾은 경우

캐시미스: 원하는 데이터가 캐시에 없어 주 메모리로 가서 데이터를 찾아오는 경우

### 캐시매핑

캐시가 히트되기 위해 매핑하는 방법으로 CPU의 레지스터와 주 메모리 간에 데이터를 주고받는 것을 기반으로 설명함

- 직접 매핑: 주 기억장치의 블록들이 지정된 한 대의 캐시라인으로만 사상될 수 있는 매핑 방법
    
    간단하고 구현 비용이 적게 들지만 적중률이 낮아질 수 있음, 속도 빠름
    
- 연관 매핑: 직접 매핑의 단점을 보완한 방식으로 순서를 일치시키지 않고 관련 있는 캐시의 메모리를 매핑하는 방식
    
    모든 태그들을 병렬로 검사해야 하기 때문에 복잡하고 비용이 높음, 속도 느림
    
- 집합 연관 매핑: 직접 매핑과 연관 매핑의 장점만을 취한 방식으로 순서는 일키시키지만 집합을 둬서 저장함
    
    집합화가 되어 있기 때문에 검색이 효율적
    

## 웹 브라우저의 캐시

### 쿠키

만료 기한(보통 서버에서 지정)이 있는 키-값 저장소로 same site 옵션을 strict로 설정하지 않은 경우 다른 도메인에서 요청 시 자동 전송됨

4KB까지 데이터 저장 가능

- Session Cookie: 메모리에만 저장되며 만료 시간이 있지만 브라우저 종료 시 삭제
- Persistent Cookie: 파일로 저장되며 Max-Age 설정을 통해 장기간 유지 가능하고 브라우저 종료와 관계없이 사용 가능한 쿠키
- Secure Cookie: HTTPS에서 사용되는 암호화된 쿠키로 비교적 안전하지만 실질적 보안이 제공되지 않아 민감한 데이터 저장 금지
- Third Party Cookie: 다른 도메인에 요청이 필요할 때 생성하는 쿠키로 주로 광고 목적으로 사용됨

### 웹 스토리지

만료 기한이 없는 키-값 저장소로 데이터 용량이 넉넉함 (모바일: 2.5MB, 데스크탑: 5~10MB)

문자열 외에도 자바스크립트의 모즌 원시형 데이터와 객체 저장 가능

도메인 단위로 접근이 제한되는 CORS 특성 때문에 CSRF로부터 안전함

HTML5를 지원하는 브라우저만 사용 가능하다는 단점이 있음

- 로컬 스토리지: 웹 브라우저를 닫아도 유지됨
- 세션 스토리지: 탭 단위로 생성하기 때문에 탭이 닫히면 데이터도 삭제됨

## 데이터베이스의 캐싱 계층

데이터베이스 시스템의 경우에도 메인 데이터베이스 위에 레디스 데이터베이스 계층을 캐싱 계층으로 두어 성능을 향상시키기도 함

# 메모리 관리

## 가상 메모리

메모리 관리 기법의 하나로 컴퓨터가 실제로 이용 가능한 메모리 자원을 추상화하여 이를 사용하는 사용자에게 큰 메모리로 보이게 만드는 것

메모리에 해당 프로세스 전체가 올라가지 않아도 실행이 가능하다는 부분에 착안하여 고안됨

### 메모리 관리 장치(MMU; Memory Management Unit)

가상 주소를 실제 주소로 변환하고 메모리를 보호하는 기능을 수행

CPU가 각 메모리에 접근하기 이전에 메모리 주소 번역 작업이 수행됨

메모리를 일일히 가상 주소에서 실제 주소로 번역하는 경우 작업 부하가 높아지기 때문에 RAM을 여러 페이지로 나누어 각 페이지를 하나의 독립된 항목으로 처리

<aside>
💡 페이지 테이블: 가상 주소와 실제 주소가 매핑되어 있고 프로세스의 주소 정보가 들어있는 테이블
→ 속도 향상을 위해 TLB를 사용

TLB: 메모리와 CPU 사이에 있는 주소 변환을 위한 캐시로 페이지 테이블에 있는 리스트를 보관하여 CPU가 페이지 테이블까지 가지 않도록 함

</aside>

### 페이지 폴트

가상 메모리에는 존재하지만 RAM에는 부재할 때 뜨는 인터럽트

페이지 폴트가 발생하면 운영체제는 데이터를 메모리로 가져와 페이지 폴트가 발생하지 않은 것처럼 프로그램이 계속적으로 작동하게 함

⇒ 스와핑: 페이지 폴트 방지를 위해 당장 사용하지 않는 영역을 하드디스크로 옮기고 필요할 때 다시 RAM으로 불러오는 방식으로 RAM을 관리하는 것

페이지 폴트와 그로 인한 스와핑 과정

1. CPU가 물리 메모리 확인
2. 페이지가 없는 경우 트랩을 발생시켜 운영체제에 알림
3. 운영체제는 CPU의 동작을 잠시 멈춤
4. 운영체제가 페이지 테이블을 확인하여 가상 메모리에 페이지가 존재하는지 확인
5. 페이지가 없으면 프로세스 중단 후 물리 메모리에 비어 있는 프레임이 있는지 확인
6. 비어 있는 프레임에 해당 페이지 로드 후 페이지 테이블 최신화
7. CPU 재시작

### 스레싱

메모리의 페이지 폴트율이 증가하여 CPU 이용율이 급격하게 떨어지는 현상

프로세스를 처리하는 시간보다 메모리에 적재되지 못한 페이지 때문에 페이지 교체에 드는 시간이 많은 경우 발생

동시 실행 프로세스가 많아질수록 각 프로세스에 할당된 메모리 페이지 프레임이 작아짐 → 적은 페이지 프레임을 할당받은 프로세스들의 페이지 폴트 증가 → 스와핑 증가 → CPU 이용율 감소

스레싱 해결 방법

- working set
    
    지역성의 원리를 이용하여 지역성 집합이 메모리에 동시에 올라갈 수 있도록 보장하는 메모리 관리 방법
    
- PFF(Page Fault Frequency)
    
    프로세스의 페이지 폴트율을 주기적으로 조사하고 이 값에 근거해 각 프로세스에 할당할 메모리 양을 동적으로 예측, 조절하는 알고리즘
    
    현재 페이지 폴트와 직전 페이지 폴트 사이의 시간을 관찰하여 상한값을 초과하거나 하한값 미만이 되는 경우 운영체제가 메모리에 올라가 있는 프로세스의 수 조절
    

## 메모리 할당

### 연속 할당

메모리에 연속적으로 공간을 할당하는 것

- 고정 분할 방식
    
    물리적 메모리를 주어진 개수만큼의 영구적인 분할로 미리 나누어 두고 각 분할에 하나의 프로세스를 적재해 실행
    
    동시에 메모리에 올릴 수 있는 프로그램의 수가 고정되어 있으며 수행 가능한 프로그램의 최대 크기도 제한되기 때문에 융통성이 떨어짐
    
    내부 단편화 발생 가능
    
- 가변 분할 방식
    
    메모리에 적재되는 프로그램의 크기에 따라 분할의 크기, 개수가 동적으로 변하는 방식
    
    외부단편화 발생 가능
    
    동적 메모리 할당 문제: 프로세스 종료 시 메모리 내의 여러 곳에 산발적으로 메모리 가용 공간이 생기는데 이때 새로운 프로그램을 적재하기 위해 가용 공간 중 어떤 위치에 올릴 것인지 결정하는 방법
    
    - 최초 적합: 크기가 N 이상인 가용 공간 중 가장 먼저 찾아지는 곳에 프로그램을 할당 (시간적 측면에서 효율적)
    - 최적 적합: 크기가 N 이상인 가용 공간 중 가장 작은 가용 공간을 찾아 프로그램을 할당 (공간적 측면에서 효율적)
    - 최악 적합: 가용 공간 중 가장 크기가 큰 곳에 프로그램 할당

<aside>
💡 외부 단편화: 프로그램의 크기보다 분할의 크기가 작아 해당 분할이 비어있음에도 프로그램을 적재하지 못하는 현상

내부 단편화: 프로그램의 크기보다 분할의 크기가 큰 경우 해당 분할에 프로그램을 적재하고 남는 현상

</aside>

### 불연속 할당

현대 컴퓨터 시스템이 주로 사용하는 방식으로 하나의 프로세스가 물리적 메모리의 여러 위치에 분산되어 올라갈 수 있는 메모리 할당 기법

- 페이징
    
    프로세스의 주소 공간을 동일한 크기인 페이지 단위로 나누어 물리적 메모리의 서로 다른 위치에 페이지를 저장하는 방식
    
    각 프로세스의 주소 공간 일부는 백킹 스토어에, 일부는 메모리에 혼재시키는 것이 가능함
    
    홀의 크기가 균일하지만 주소 변환이 복잡해짐
    
- 세그멘테이션
    
    페이지 단위가 아닌 세그먼트 단위로 나누는 방식
    
    세그먼트의 경우 의미 단위로 구성되어 있음
    
    의미 단위로 쪼개져 있어 권한 부여 및 공유가 자연스러움 (페이징 방식의 경우 code, data, stack이 각각 다른 페이지 프레임에 쪼개져 들어가기 때문에 권한 작업이 어려움)
    
    홀 크기가 균일하지 않음
    
- 페이지드 세그멘테이션
    
    공유나 보안을 의미 단위인 세그먼트로 나누고 물리적 메모리는 페이지로 나누는 것
    
    둘의 장점을 결합
  
## 페이지 교체 알고리즘

프로세스가 요구한 페이지가 현재 메모리에 없으면 페이지 부재(page fault)가 발생한다. 페이지 부재가 발생하면 스왑 영역에서 페이지를 메모리로 가져오는데, 만약 메모리가 꽉 찼다면 메모리에 있는 페이지를 스왑영역으로 보내야 한다. 

→ 페이지 교체 알고리즘은 **스왑 영역으로 보낼 페이지를 결정하는 알고리즘**으로, 메모리에서 앞으로 사용할 가능성이 적은 페이지를 **대상 페이지(victim page)**로 선정하여 페이지 부재를 줄이고 시스템의 성능을 향상한다.

## 페이지 교체 알고리즘의 종류

### 무작위 페이지 교체 알고리즘 (Random)

가장 간단하게 구현할 수 있는 알고리즘

스왑 아웃될 대상 페이지를 특별한 로직 없이 무작위로 선정

지역성을 전혀 고려하지 않음

성능이 좋지 않아 거의 사용되지 않음

### FIFO 페이지 교체 알고리즘 (First In First Out)

시간 상 메모리에 가장 먼저 들어온 페이지를 대상 페이지로 선정

메모리가 꽉 차면 맨 위 페이지가 스왑 영역으로 가고, 나머지 페이지들이 위쪽으로 이동, 새 페이지가 아래쪽으로 들어옴

무조건 오래된 페이지를 대상 페이지로 선정하므로 성능이 좋지 않음

### 최적 페이지 교체 알고리즘 (Optimal)

앞으로 사용하지 않은 가능성이 제일 높은 페이지를 대상 페이지로 선정

이상적인 방법이지만 실제로는 미래의 접근 패턴을 알고 구현할 수 없음

### LRU 페이지 교체 알고리즘 (Least Recently Used)

가장 오랫동안 사용되지 않은 페이지를 스왑 아웃

구현 방식

- 페이지 접근 시간에 기반한 구현
- 카운터에 기반한 구현
- 참조 비트 시프트 방식

### LFU 페이지 교체 알고리즘 (Least Frequently Used)

페이지가 몇 번 사용 되었는지를 기준으로 대상 페이지를 선정

즉, 현재 프레임에 있는 페이지마다 그동안 사용된 횟수를 세어 횟수가 가장 적은 페이지를 스왑 아웃

메모리의 추가 공간이 필요하므로 낭비되는 메모리 공간이 많다는 단점 有

### NUR 페이지 교체 알고리즘 (Not Used Recently)

LRU, LFU 페이지 교체 알고리즘은 불필요한 메모리 공간 낭비 문제 有

NUR은 이를 개선하여 두 개의 비트만으로 구현 가능
